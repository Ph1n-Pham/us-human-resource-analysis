---
title: "Analysis of U.S. Human Resources Data"
author: "Phineas Pham, Harry Kim, Nova Nguyen"
date: "11/18/2021"
output:
  html_document:
    code_folding: hide
---

## INTRODUCTION

  Our data set is produced by the U.S Office of Personnel Management, providing statistical information about the Federal civilian workforce. This particular dataset is the newest quarterly update, consisting of U.S workforce data collected in June 2021. The purpose of this raw data set is to increase public access to high value, machine readable datasets, and they are accessible via https://www.opm.gov/data/. The original dataset contains more than two million observations and about 30 variables about each employee, such as their salary, length of service under the federal government, highest education level and so on.
  
  Approaching this dataset, our group would like to explore what the employment landscape is like under the U.S Federal government, as well as what factors affect the salary of an average Federal civilian employee. Particularly, we want to look at this dataset from the perspective of an undergraduate student looking for stable employment within the States. Hence, we have filtered the dataset we will work with to only contain information of employees posted within U.S territory and working full-time, which narrows our dataset down to just more than 30,000 observations that will be more substantial to our questions. Our approach to our first main question about the employment landscape under the U.S. federal government involve visually mapping out certain variables and how some of them might relate to each other. This is a broad, exploratory question for which we do not have any end hypothesis to test. From here, we could select variables of interest that might be more predictive of an average employee's salary to put them in a multiple regression, therefore answering our second question about what factors determine salary for the U.S. Federal workforce.
  <br>
  <br>
  
  
  
  
## ETHICAL CONSIDERATIONS
  
  For our analysis, the U.S federal government and its employees are the biggest stakeholders as they are the source of the dataset we are working with. Even though the nature of our analysis is purely exploratory with no intention of assessment nor critique regarding the U.S. federal government's Human Resource management, any findings we have might still directly impact them via third-party interpretation of our research. Additionally, the future workforce (especially those interested in insights of the Federal employment landscape) is one of our stakeholders as they may make future decisions based on our analysis. The dataset we used is public information, has been de-identified and declassified, so we believe there would be no personal negative impacts to the employees, making our work ethically responsible. We also made sure to adhere to the three principles of the Belmont Report at every juncture while we worked on our analysis.
  <br>
  <br>
  
  
  
  
## DATASET OVERVIEW AND EXPLANATION

#### Data wrangling process:

```{r setup, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Include libraries:
library(dplyr)
library(ggplot2)
library(readr)
library(ggthemes)
library(maps)
library(GGally)
library(MASS)
library(RColorBrewer)
library(grid)
library(gridExtra)
library(lindia)
```

```{r, results = FALSE, message = FALSE, warning = FALSE}
#Read in dataset
employment <- read_delim("FACTDATA_JUN2021.txt")

#Choose specific columns
employment <-  employment %>% 
  dplyr::select("LOC", "AGELVL", "EDLVL","PATCO", "STEMOCC", "SUPERVIS", "WORKSCH", "WORKSTAT", "SALARY", "LOS")

#Change data types:
employment$LOC <- as.numeric(employment$LOC)
employment$AGELVL <- factor(employment$AGELVL, levels = c("A","B","C","D","E","F","G","H","I","J","K"),
                            labels = c("<20","20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", ">60"))

#Filter out locations not in U.S. and non-values
employment <- employment %>%
  filter(LOC == c("1", "2", "4", "5", "6", "8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "44", "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56"))
employment$AGELVL %>%
  na_if("Z")
employment$EDLVL %>%
  na_if("**")
employment$PATCO %>%
  na_if("Unspecified")
employment$WORKSCH %>%
  na_if("**")
employment$SUPERVIS %>%
  na_if("**")
employment$LOC %>%
  na_if("**")

employment <- employment %>%
  filter(WORKSTAT == 1) %>%               #Filter only full-time position:
  dplyr::select("LOC", "AGELVL", "EDLVL","PATCO", "STEMOCC", 
                "SUPERVIS", "SALARY", "LOS") %>%     #Choose specific columns
  mutate(jobtype = ifelse(STEMOCC == "XXXX", "nonSTEM", "STEM"))             #Specify STEM and nonSTEM variables

#Change data types:
employment$SALARY <- as.numeric(employment$SALARY)
employment$LOS <- as.numeric(employment$LOS)
employment$EDLVL <- as.numeric(employment$EDLVL)

#Change age code to numeric values
employment <- employment %>%
  mutate(avgAGELVL = factor(employment$AGELVL, levels = c("<20","20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", ">60"), labels = c(15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65)))

#Change states code to name
employment$LOC <- factor(employment$LOC, levels = c("1", "2", "4", "5", "6", "8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "44", "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56"),
                            labels = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "District of Columbia", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"))
```

  A preview of the dataset after our wrangling process:
  
```{r, message = FALSE, warning = FALSE}
head(employment, 8)
```

  In total, we will use over 32,000 observations (employees) and 8 base variables. Fortunately, the data set has been pre-organized to be tidy data, with the overall data set formatted in a rectangular layout, and with each cell containing only one information. Each row of observations represent information about one employee. From left to right, the variables we analyzed include: which State the employee works in (LOC), their age category (AGELVL), highest education level represented by ordinal numbers (EDLVL), type of occupation (PATCO), whether or not their occupation is related to STEM fields (STEMOCC), supervisory role (SUPERVIS), yearly salary (SALARY), and average length of service under the U.S. federal government (LOS).
  
  As aforementioned in the introduction, we have filtered the original dataset from over 2 million U.S. federal government employees to better match our target of analysis, which only contains employees working full time within the U.S. national boundary. The majority of our data wrangling process involved turning existing unspecified/unrecorded observation cells with NA values, and renaming how observations are recorded in the dataset. For example, in the original dataset, states were recorded in representative numbers, which we have converted into names to make it easier for both our analysis process and result communication. Additionally, we also had to decide on how to treat our data, whether as categories or numbers. For example, under certain assumptions, ordinal categorical values such as highest education level can be represented as quantitative values for ease of fitting into a statistical model. We eventually decided against adopting this method, in order to provide a more accurate analysis on such variables.
  <br>
  <br>




## U.S. FEDERAL GOVERNMENT EMPLOYMENT LANDSCAPE EXPLORATION

#### 1. Salary distribution
```{r, warning = FALSE, message = FALSE}
ggplot(employment, aes(x = SALARY)) + 
  geom_histogram(col = "darkgreen", fill = "lightgreen") + 
  theme_minimal() + 
  labs(title = "Income Distribution of Federal Gov Employees")
```
  
  From the graph above, it can be seen that majority of the federal employee salary ranges from about 50,000 - 120,000 a year, with the median at about 86,000. This is quite a considerable amount compared to the median individual income in the U.S., reportedly 45,000 in 2021. Hence, for those seeking employment whose biggest concern is the amount of salary, we would say that this is quite a substantial amount.
  <br>
  <br>
  
#### 2. How does salary differ among different age groups?
```{r, warning = FALSE}
ggplot(employment, aes(x = AGELVL, y = SALARY)) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(title="Salary Distribution based on Age group", x = "Age Group", y = "Salary ($)")
```
  
  Since promotion prospects and salary increase are important factors for many people when they pick a job, we made a visualization that shows the difference in salary between each age group. From the graph above, we can see that median yearly salary increases as age group increases at a decreasing rate. Median yearly salary increases from about 30,000 at below 20 years old until 45-49 age group, and seems to flatten out at about 90,000 - 100,000 from 50 years old and above. Thus, we can conclude that, under the U.S. federal government, employees do receive a steady increase in salary throughout their career which may cap out only in the later phase of their career. 
  <br>
  <br>
  
#### 3. Map Visualization of mean salary by states

```{r, warning = FALSE}
state <- employment %>%
  dplyr::select(SALARY, LOC) %>%
  group_by(LOC) %>%
  summarize(meanSAL = mean(SALARY, na.rm = TRUE))

states_map <- map_data('state')

state <- state %>%
  mutate(region = tolower(LOC))
states_map <- left_join(states_map, state, by = "region")

ggplot(states_map, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = meanSAL), col="light blue") +
  scale_fill_viridis_c(option = "I") +
  theme_void()

```
  
  Our group considered location as an important factor in seeking employment since the cost of living is different in each state. As we can see, states that have higher cost of living such as California, Massachusetts, and New York are reasonably offset by higher mean salaries. However, states with the highest mean salary for an average U.S. federal government employee actually lie around the East Coast, notably the District of Columbia and Maryland, with mean salary at about 120,000. We speculate that it is due to the fact that the major government agencies such as the White House, Pentagon, etc. is concentrated in Washington D.C., thus leading to a significant number of higher-ranking employees to work in the area, thus leading to a higher mean salary for the state as a whole. 
  <br>
  <br>

#### 4. For those of the 20-35 age group, what is the occupation category with the highest salary? 
```{r, warning = FALSE}
employment$PATCO <- factor(employment$PATCO, levels = c(1,2,3,4,5,6,9),
                           labels = c("Professional", "Administrative", "Technical","Clerical", 
                                      "Other White Collar", "Blue Collar", "Unspecified"))

data3 <- employment %>%
  dplyr::select(PATCO, AGELVL, SALARY) %>%
  filter(AGELVL == c("20-24", "25-29", "30-34")) %>%
  group_by(PATCO) %>%
  summarize(meansal = mean(SALARY, na.rm = TRUE))

ggplot(data3, aes(x = PATCO, y = meansal, fill = PATCO)) + 
  geom_col() + theme_minimal() + 
  theme(axis.text.x = element_text(angle = 20)) + 
  labs(title = "Mean Salary for Different Profession Types", y = "Salary ($)", 
       x = "Occupational Categories") + 
  scale_fill_manual(values = c("pink", "light green", "yellow", "purple", "grey", "light blue") ) +
  theme(legend.position="none") 
```
  
  Our group predicted that the salary given can be very different in regards to the profession type one will work as. According to the code book, we know that professional job has the highest responsibility, decreasing to blue collar having the lowest responsibility, as their order in the graph. As we can see in the graph, the professionals get the highest mean salary as anticipated because they require the highest education among all other types. The next comes Administrative. We suspected this role has the second highest salary due to amount of work and responsibility they have. One thing that we didn't expect from this analysis is that blue collar job has the 3rd highest salary. According to the the government's code book, blue collar job consist of experts in certain area such as electricians, plumbers, etc. Since they need to be really experienced and follow the confidentiality policy if they work in a secrete facility, we think the pay rate is higher than the other profession types.
  <br>
  <br>
  
#### 5. Has there been any change in employers' demand for a bachelor degree for full-time positions under the federal government over time?

```{r, warning = FALSE}
EDLVL1 <- employment %>%
  dplyr::select(EDLVL, AGELVL)
#EDLVL1$EDLVL <- as.numeric(EDLVL1$EDLVL)
EDLVL1 <- EDLVL1 %>%
  group_by(AGELVL) %>%
  summarize(college = sum(EDLVL >= 13, na.rm = TRUE), 
            noncollege = sum(EDLVL < 13, na.rm = TRUE), 
            total = college + noncollege, 
            perc_col = college/total*100)

ggplot(EDLVL1, aes(x = AGELVL, y = perc_col)) + 
  geom_col(fill = "lightblue") + 
  ylim(0,100) + 
  theme_minimal() + 
  labs(title = "Percentage of All Employees with BA", x = "Age level", y = "Percentage")
```

```{r, warning = FALSE}
EDLVL2 <- employment %>%
  filter(PATCO == "Professional") %>%
  dplyr::select(EDLVL, AGELVL)
#EDLVL2$EDLVL <- as.numeric(EDLVL2$EDLVL)
EDLVL2 <- EDLVL2 %>%
  group_by(AGELVL) %>%
  summarize(college = sum(EDLVL >= 13, na.rm = TRUE), 
            noncollege = sum(EDLVL < 13, na.rm = TRUE), 
            total = college + noncollege, 
            perc_col = college/total*100)

ggplot(EDLVL2, aes(x = AGELVL, y = perc_col)) + 
  geom_col(fill = "lightblue") + 
  ylim(0,100) + 
  theme_minimal() + 
  labs(title = "Percentage of Professional Employees with BA", 
       x = "Age level", y = "Percentage")
```


  Another important factor to consider for people seeking employment is education requirements to better align their profiles with employers' demands. Assuming that employees tend to be recruited around a certain age, 25-30 in their prime for example, we take age groups to be a measurement of time change. As we can see from the two visualizations above, there has generally been not much change in the percentage of employees with at least a bachelor degree over time, stabilizing around 50% across all types of profession, and at 90% for employees working as professionals. However, we are unable to deduce whether bachelor degrees greatly affect one's chances of being employed under the U.S. federal government as we do not have information on profiles of those applied for employment to compare with our dataset, employees that have successfully been recruited. 
  <br>
  <br>
  
#### 6. Is there a higher demand for STEM occupations in recent years?
```{r, warning = FALSE}
myPalette <- brewer.pal(2, "Set2") 

data4 <- employment %>%
  dplyr::select(jobtype, AGELVL)

data6 <- data4 %>% 
  group_by(jobtype) %>% 
  summarise(perc_nonSTEM = sum(jobtype == "nonSTEM", na.rm = TRUE) / 32359 * 100, perc_STEM = sum(jobtype == "STEM", na.rm = TRUE) / 32359 * 100)
Prop <- c(71.34028, 28.65972)

#pie(Prop, labels = c("nonSTEM", "STEM"), border="white", col=myPalette)

data5 <- employment %>%
  dplyr::select(jobtype, AGELVL) %>%
  filter(AGELVL == c("20-24", "25-29"))
data7 <- data5 %>% 
  group_by(jobtype) %>% 
  summarise(perc_nonSTEM = sum(jobtype == "nonSTEM", na.rm = TRUE) / 1066 * 100, 
            perc_STEM = sum(jobtype == "STEM", na.rm = TRUE) / 1066 * 100)
Prop2 <- c(68.85553, 31.14447)

#pie(Prop2, labels = c("nonSTEM", "STEM"), border="white", col=myPalette)

par(mfrow=c(1,2))
pie(Prop, labels = c("nonSTEM", "STEM"), border="white", col=myPalette, main = "All age groups")
pie(Prop2, labels = c("nonSTEM", "STEM"), border="white", col=myPalette, main = "20-29 age group")

```

  Prior to analyzing STEM and Non-STEM occupations, our group suspected that there will be an increase in STEM occupations in recent years since there has been an increase in technology in any type of organizations nowadays. But the result was surprisingly different. From the two pie charts above, we can see that there is a very slight increase in the number of employees of age 20-29 in STEM fields under the U.S. federal government compared to the whole age groups. We do not believe this is substantial enough to indicate that there is a higher demand for STEM or non-STEM occupations for new employees. However, this visualization makes it concrete that the Federal Government offers significantly more non-STEM occupations than STEM.
  
  <br>
  <br>
  
## LINEAR REGRESSION AND STATISTICAL TESTS

#### How and which variables factor into an employee's salary?

  We have chosen 6 variables that might be useful in predicting an average employee's salary, including age level, length of service, job type (whether or not it is related to STEM fields), education level, supervisor role, and occupation category (PATCO. We will first attempt to validate our model by running a multicollinearity test to see whether these variables are substantially correlated, therefore potentially skewing the predictive model.
  
```{r, warning = FALSE, message = FALSE}
employment <- employment %>%
  filter(PATCO != "Unspecified")
employment$avgAGELVL <- as.numeric(employment$avgAGELVL)
employment$EDLVL <- as.numeric(employment$EDLVL)
ggpairs(employment, columns = c("avgAGELVL", "LOS", "jobtype", "EDLVL", "SUPERVIS", "PATCO"))
```
  
  As seen from above, with the exception of LOS and avgAGELVL which has a moderately significant correlation value of 0.547, all other variables have rather low correlation with one another. This means that length of service and age level have a rather close relation with each other, which is reasonable considering that those who have spent more time working under the U.S. federal government would likely have a higher age. From this analysis, we have decided to use length of service instead of age as a predictor for our model, as we believe that an employee is more likely rewarded according to their abilities, experience and commitment to their job. Thus, we have narrowed our predictors down to 5 variables: LOS, EDLVL, SUPERVIS, jobtype, and PATCO.
  <br>
  <br>
  
#### LINEAR MODEL TO PREDICT SALARY
  
  Next, we will make a multi-variable regression out of our chosen predictors to analyze how they affect salary.
  
```{r, warning=FALSE}
mod1 <- lm(SALARY ~ LOS + jobtype + EDLVL + SUPERVIS + PATCO, data = employment)
summary(mod1)
```
  
  Going into details about the linear model, the value of adjusted R-squared at 0.4616 tells us that our 5 predictors account for 46.16% of the variance in salary under the U.S. federal government, which is a moderately substantial amount. The intercept value is a hypothetical figure for us to compare how changes in the dependent variables affect salary. Fortunately, the p-value of all of our predictors are below 0.05, which means that they all have a statistical significance in changes in salary amount. 
  
  To summarize, every 1 year increase in length of service leads to about 951 increase in salary. Compared to non-STEM occupations, STEM employees receive 7,461 more in salary each year. Every 1 year of increase in education level leads to about 1,528 increase in yearly salary for an employee. Every 1 level of increase in supervisor rank leads to 3,683 increase in salary. Compared to Professional occupations, Administrative employees are paid 8,181 less in salary. Others are paid significantly less compared to Professional employees: Technical employees at 41,886; Clerical at 51,635; White collar at 38,292; Blue Collar at 36,186.
  <br>
  <br>
  
#### MODEL VALIDATION
  
```{r, warning = FALSE}
selectmod <- stepAIC(mod1)
selectmod$anova
```
  
  The stepAIC program calculates which regression model is most suitable for defining a dependent variable and how many predictors should be used for that model. AIC estimates the quality of a statistical model, for a given set of data, relative to other models. The initial model is our team's proposed linear regression as above, and it is exactly the same as the final model. This means that our model is statistically sound, and we have a basis to believe that we can use our 5 chosen variables to predict an employee's salary.
  
  Next, we will check whether the residual variance is normally distributed. Residuals refer to the difference in value between a real observation from our dataset and the proposed output predicted by our linear regression. We can validate our model by checking whether residuals are normally distributed to give us an indication on whether our base assumptions about how our predictors factor into salary are valid.
  
```{r, warning = FALSE, message = FALSE}
plots <- gg_diagnose(mod1, plot.all=FALSE)

plots$residual_hist
```

  From the first plot, the residual histogram, we can see that the median falls around 0, and there is a generally even distribution of residuals on either side of this median. This means that the residual histogram does follow the normal distribution curve, and indicates that our model's underlying assumptions are valid.
  
```{r, warning = FALSE, message = FALSE}
plots$qqplot
```

  Next, the Normal-QQ plot is another visualization to check the normal distribution of residuals where we compare the dataset's residuals to a theoretical normal distribution. From the qqplot above, the points fall along the red line in the middle of the graph, but curve off in the extremity to the right. Normal-QQ plots that exhibit this behavior usually mean our data have more extreme values than would be expected if they truly came from a Normal distribution. Going forward, we can set aside these extreme values to provide a more accurate prediction of salary.

```{r, warning = FALSE, message = FALSE}
plots$scalelocation
```

  From the scale-location plot, we can see that the red line (which represents fitted values for the residuals) are roughly horizontal until it gets skewered downward at the end to account for a stray extreme value. Setting aside this extreme value, we can conclude that the model has relatively constant variance of the residuals. The model also shows that, for the major concentration of points, there is a roughly equal spread of points around the red line, which means that variability of magnitudes doesn't change much with the fitted values. Hence, for the most part, we can use the base linear model.
  <br>
  <br>
  
#### IS A HIGHER DEGREE WORTH IT?
  
  Due to the constraint in how many categories from each predictor R can accept, we decided to treat education level (EDLVL) as a discrete quantitative variable instead of categorical in the linear model above. To provide a more accurate analysis, we will conduct a separate statistical test to analyze the difference in yearly salary for employees with at least a bachelor degree compared to those with a higher qualification. 
  
```{r, warning = FALSE}
#Create 2 datasets only has education level and salary
bach_sal <- employment %>%
  dplyr::select(EDLVL, SALARY) %>% 
  filter(EDLVL >= 13 & EDLVL < 17)
mas_sal <- employment %>%
  dplyr::select(EDLVL, SALARY) %>% 
  filter(EDLVL >= 17)

#Run t-test 
t.test(bach_sal$SALARY, mas_sal$SALARY)
```

  This t-test investigates the difference in the mean salary of employees who have at least bachelor degree but have not reached master degree, and those who have a master degree or higher. The p-value of 2.2e-16, less than 0.05, shows us that there is a statistically significant difference in the salary between these two groups. The 95 percent confidence interval shows that 95% of the observations will have the difference in the range of 6020 and 8561. To us, this is a really small difference in the salary between bachelor-degree owners and master-degree owners. In the costly tuition of getting master degrees in the U.S., we think it would not be a good idea to reach for master degree if the main purpose is to achieve a higher salary.
  <br>
  <br>

## CONCLUSION

  To summarize, some of the findings that we have drawn from this dataset and might be of interest to those looking for employment under the U.S. government include:
  <br>
  <br>
  - The median yearly salary of an average U.S. federal government employee is about 86,000 which is much higher than the average U.S. individual yearly salary of 45,000
  <br>
  <br>
  - There is a healthy growth in salary over employees' age range until their late career (50 years old and above)
  <br>
  <br>
  - On average, Professional and Administrative employees earn higher salary than other occupational categories
  <br>
  <br>
  - There is not much change over the years in demand for employees with at least a bachelor degree, averaging 50% for all job types and 90% for Professional employees in specifics
  <br>
  <br>
  - There is a slightly higher, but not too substantial, demand for STEM related occupations under the U.S. federal government in recent years
  <br>
  <br>
  - We would advice against pursuing a higher education than undergraduate if the purpose is purely to earn a higher income under the U.S. government. This is because the average increase in salary from earning a higher degree compared to having a bachelor degree (about 6020-8500) is not significant enough to offset the cost of higher education. This is supported by an article published by FedSmith.com, a free source of information impacting the federal community and those interested in the federal government's activities, which states that "once you have enough education, the pay takes a hit. Those with professional degrees that took years of study and hard work are actually paid significantly less when working as a federal employee. This is because working for the government guarantees you a steady salary since you always have work."
  
  
  Regarding our linear model to predict an employee's average income, we conclude that the R squared value of 0.4618, or accounting for 46.18% of the variance of a federal employee's salary, is not too substantial and that we have a lot of room to improve our model to better predict salary. We realize that, due to the constraint of our dataset, there are other intuitive factors that might go into deciding one's salary level, such as their performance rating, maybe even other hidden factors such as one's personal backgrounds. There is another published study by the FEDcube that tracks their employees' racial backgrounds. Going forward, we could incorporate analyses of this dataset with our own salary dataset to better understand the employment landscape and factors affecting salary under the U.S. federal government.
  <br>
  <br>
  
#### References
Is a Graduate Degree Worth It? (Kay, J., Sep 12, 2017) https://www.fedsmith.com/2017/09/12/graduate-degree-worth/
